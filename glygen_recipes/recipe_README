Recipe files README
-------------------------------------------------------------------------------------
Index:

Summary

Example Recipe

Recipe Actions

Use-case Examples

Running the Script

Troubleshooting


-------------------------------------------------------------------------------------
Summary
-------------------------------------------------------------------------------------
Recipe files are used to describe the actions that the script "make-datasets.py" will perform on a ".csv" dataset file, to process the dataset for integration into a OncoMX or Glygen. 

Recipe files are in ".json" format. For more information on the ".json" format, go to www.json.org

The recipe consists of two major sections "outputfiles" and "tablelist". 

Put simply, in "tablelist" you will create tables from the list of "actions" that can be performed. 

You will then use "outputfiles" to denote what tables you wish to export and the content to include from those tables. 

The "outputfile" is typically the reformatted dataset ".csv" that will then move forward in the pipeline to eventually be included on the frontend of OncoMX or Glygen. 


-------------------------------------------------------------------------------------
Example Recipe
-------------------------------------------------------------------------------------
###
Below is an recipe file with comments: 
###

{
    "outputfiles": [
        {
            "fields": [
			
		# for fields, the name must be a name that has been given in the tablelist section below
		# these are often field names from the input datasets, but also can be fieldnames generated from actions
		# newname is the fieldname that will be generated in the output file and replace the old field name
                {
                    "newname": "gene_symbol",
                    "name": "Gene Symbol"
                },
				{
                    "newname": "uniprot_ac",
                    "name": "Uniprot AC"
                },
				{
                    "newname": "chr_num",
                    "name": "Chr Num"
                },
				{
                    "newname": "chr_pos",
                    "name": "Chr Pos"
                },
				{
                    "newname": "ref_nt",
                    "name": "Ref NT"
                },
				{
                    "newname": "alt_nt",
                    "name": "Alt NT"
                }
            ], 
			
	    # the tableid denotes what table from the tablelist will be used for this output file
            "tableid": 3, 
			
	    # the masterlistfilter field denotes the fieldname that is used as the primary field name for filtering(?)
            "masterlistfilterfield":"gene_symbol",
			
            # the filepath gives the name and path for the outputfile
            "filepath": "unreviewed/example_dataset.csv"
        }
    ], 
    "tablelist": [
        {
	    # every table in tablelist has a tableid, which can be referenced by other actions or the outputfile 
            "id": 1,
			
	    # input denotes we are taking a file in from the filepath listed
	    "type": "input",
			
	    # the separator denotes the structure of the input file
	    # here the separator is 'doublequote comma doublequote' so each line of the input file looks like this "a","b","c" 
	    "separator": "\",\"",
			
	    # list of the fields in the inout file
            "fields": [
                "Uniprot AC",
                "Chr Num", 
                "Chr Pos",
                "Ref NT", 
                "Alt NT",
		"EXAC Alt Frequency",
		"1000 Genomes Alt Frequency"
            ],
            "filepath": "downloads/example_mutations.csv"
        },
	{
	    # same as above for table '"id":1', but for a different input file
	    "id": 2,
	    "type": "input",
            "separator": "\",\"", 
            "fields": [
                "uniprot accession",
                "Gene Symbol" 
            ],  
            "filepath": "downloads/example_mapping.csv"
        },
	{
	    # this table performs an action
	    "id": 3,
			
	    # the type is output so it will be generating a new table based on the action used
	    "type": "output",  
			
	    # what other tables are being used to generate this new table. In this case our inout files from tables 1 and 2
	    "inputtables":[1,2],
			
	    # what action will be taken to make the new table
	    "action":{
			# the name gives the specific action to take
			"name":"jointables",
				
			# different actions have their own parameters. In this case the jointables action has only the parameter anchorfields.
			# specific details on actions are below in the README
			"anchorfields":["Uniprot AC", "uniprot accession"]
	    }
        }
    ]
}

-------------------------------------------------------------------------------------
Recipe Actions
-------------------------------------------------------------------------------------
###
Full list of actions:
- union
- addconstantfield
- makecombofield
- filterin
- filterout
- expandrows
- transposecols
- addnormalizedcol
- addaveragecol
- splitcol
- jointables

###
union 
###
###Summary

Merge multiple tables and remove duplicate lines.

###Format:

{
	"id":#,
	"type":"output",
	"inputtables":[#,#,#],
	"action":{
		"name":"union"
	}
}

###Notes:
This action can take any number of inputtable tables. 


###
addconstantfield 
###
###Summary

Needs clarification from Robel

Add a new field to the table that has an entry for each line(?)

###Format:

{
	"id":#,
	"type":"output",
	"inputtables":[#,#,#],
	action":{
		"name":"addconstantfield",
		"newfields":{
			"example_field_1":"example_entry_1",
			"example_field_2":"example_entry_2"
			}
	}
}

###Notes: 
This action can take multiple inputtable tables. 


###
makecombofield
###
###Summary

Combine two fields into one field. 

###Format:

{
	"id":#,
	"type":"output",
	"inputtables":[#],
	"action":{
		"name":"makecombofield",
		"fieldlist":[
			"example_field_1",
			"example_field_2"
			],
		"merge_char":"|",
		"combofield":"example_combo_field"
	}
}

###Notes: 
This action can take a single inputtable table. 

The above example in the format section is make the combined field example_combo_field from example_field_1 and example_field_2. 

The entries in each of the fields will merge into the combined field and be separated by the merge character, in the example the charcater is |.



###
filterin
###
###Summary

Filter only certain lines from one table into another.

###Format:

{
	"id":#,
	"type":"output",
	"inputtables":[#],
	"action":{
		"name":"filterin",
		"operation":"AND",
		"conditionlist":[
			"field":"example_field_1",
			"value":[
				"ABC",
				"-",
				""
			],
			"operation":"in"
	}
}

###Notes: 
This action can take a single inputtable table. 

In the above example, only the lines with the values ABC, -, or an empty field will be included in to a new table.



###
filterout
###
###Summary

Filter out only certain lines from a table to create a table without those entries.

###Format:

{
	"id":#,
	"type":"output",
	"inputtables":[#],
	"action":{
		"name":"filterout",
		"operation":"AND",
		"conditionlist":[
			"field":"example_field_1",
			"value":[
				"DEF"
				"123"
				"456"
			],
			"operation":"in"
	}
}

###Notes: 
This action can take a single inputtable table. 

In the above example, lines with the values DEF, 123, or 456 in the field example_field_1 will be excluded from a new table, and all other lines with other values for that field will be included.


###
expandrows
###
###Summary

For a single line that has a field with multiple data points in one field, create multiple lines where each line has a single data point from that field. 

###Format:

{
	"id":#,
	"type":"output",
	"inputtables":[#],
	"action":{
		"name":"expandrows",
		"expansionfield":"example_field_1",
		"expansiondelim":";"
		}
	}
}

###Notes: 
This action can take a single inputtable table. 

In the above example, the field example_field_1 will be used to expand rows. For every line that has the expansion delim ;, the data in that row will be separated and a new line created for each data point.

An example:

Table input: 
"example_field_1"
"data_point_1;data_point_2","information_abc"

Table output from expandrows above: 
"example_field_1","example_field_2"
"data_point_1","information_abc"
"data_point_2","information_abc"


###
transposecols
###
###Summary

Needs clarification from Robel.

The rows switch with columns and vice versa(?)

###Format:

{
	"id":#,
	"type":"output",
	"inputtables":[#],
	"action":{
		"name":"transposecols",
		"startcolidx":1,
		"newfieldone":"new_example_field_1"
		"newfieldtwo":"new_example_field_2"
		}
	}
}

###Notes: 
This action can take a single inputtable table.


###
addnormalizedcol
###
###Summary

Needs clarification from Robel.

Create a new column that takes the numerical data from an existing column and normalizes the numbers according to all other values for that field, where the max value is set to 1. 

###Format:

{
	"id":#,
	"type":"output",
	"inputtables":[#],
	"action":{
		"name":"addnormalizedcol",
		"field":1,
		"newfield":"normalized_example_field_1"
		"anchorfields":["example_field_2","example_field_3"]
		}
	}
}

###Notes: 

Use "anchorfields" do denote what field should be used to consider replicate rows. 

As an example, if there is a dataset with one gene per row and each row has a value "intensity", addnormalizedcol would create a new col that conversts the intensity number in each row to a value that is 1 or less according to its ratio with the maximum value for the field "intensity" (?)

This action can take a single inputtable table.


###
addaveragecol
###
###Summary

Need clarification from Robel. 

Create a new column that takes the average for a particlaur field from all other replicate rows (?). The average will be up to four decimal places. 

For example, if we have 3 rows that are from the same patient and gene but have different values for a field called "intensity", we can find the average value of all the rows from this patient and gene for intensity. 


###Format:

{
	"id":#,
	"type":"output",
	"inputtables":[#],
	"action":{
		"name":"addaveragecol",
		"field":"example_field_1",
		"newfield":"average_example_field_1",
		"anchorfields":["example_field_2","example_field_3"]
		}
	}
}

###Notes: 

Use "anchorfields" do denote what field should be used to consider replicate rows. 

For example, if we have 3 rows that are from the same patient and gene but have different values for a field called "intensity", we can find the average value of all the rows from this patient and gene for intensity. 

This action can take a single inputtable table.


###
splitcol
###
###Summary

Split a single column into two separate columns after specifying a deliminating character that separates the values. 

###Format:

{
	"id":#,
	"type":"output",
	"inputtables":[#],
	"action":{
		"name":"splitcol",
		"field":"example_field_1",
		"newfields":["example_field_1a","example_field_1b"],
		"delim":"|"
		}
	}
}

###Notes: 
This action can take a single inputtable table.


###
jointables
###
###Summary

Creat a new table that uses an anchor field to combine columns from multiple tables. Data wit the same anchor field value will be added to the same row in the new field. 

###Format:

{
	"id":#,
	"type":"output",
	"inputtables":[#,#,#],
	"action":{
		"name":"jointables",
		"anchorfields":["example_field_1","example_field_2"]
		}
	}
}

###Notes: 
This action can take multiple inputtable table.

-------------------------------------------------------------------------------------
Use-case Examples
-------------------------------------------------------------------------------------

There are three example data files as well as two example recipes to demonstrated impact resipe actions have on real data. 

###
Example Recipe: 
example_part1.json
example_part2.json
###

The example recipe takes all of the example data files as input. 

In the recipe each of the actions are used. To see the outcome of any one action, change the tableid option listed in the outputfiles section. 

Be sure to change the name of the outputfile in the filepath option in the outputfiles section, otherwise each time you run the recipe it will overwrite the previous output file. 

###
Example Data: 
example_mutations_1.csv
example_mutations_2.csv
example_mapping.csv
###

The contents of the data files are the following:

example_mutations_1.csv and example_mutations_2.csv contain SNP data gatehred from UCSC genome browser. 
- There are both unique and overlapping values between these two mutation files 

example_mapping.csv contains uniprot terms and their corresponsing gene symbols, which allows us to show how you can map terms from one table to terms from one table to another

-------------------------------------------------------------------------------------
Running the Script
-------------------------------------------------------------------------------------

To execute a recipe, run the following command:

python  make-datasets.py -d your_data_name

For your_data_name provide the name of the recipe before the .json, so in this case the recipe name is your_data_name.json

###Notes: 

To run the make-datasets.py script, you must be in the same folder as the script

Your recipe must be in the recipes folder

-------------------------------------------------------------------------------------
Troubleshooting
-------------------------------------------------------------------------------------

The majority of errors that prevent the script from running result from inproper formatting of the JSON file. 

In the error message you will typically receive a line number on which the error is encountered. 

To find this exact line number, while using vi to look at your recipe, type :set number and hit enter to see line numbers



